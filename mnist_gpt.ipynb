{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ca14a5e-c286-4d67-87c6-b8203d65e04e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.data import Subset\n",
    "import pandas as pd\n",
    "import math\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aba42d-a867-4d49-8b1c-34f19910c87b",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17a54337-bf6c-4a5b-ad55-ec615d35cf63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6cdb8807d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data.iloc[1].values[1:].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54450440-f39c-4600-973d-0de14bbbf4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.stop_token = 256 + 10 # 256 - 265 correspond to labels, which we can condition on\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label_token = self.data.iloc[idx].values[0] + 256\n",
    "        data = torch.tensor([label_token] + list(self.data.iloc[idx].values)[1:] + [self.stop_token], dtype=torch.long)\n",
    "        \n",
    "        inputs = data[:-1]\n",
    "        labels = data[1:]\n",
    "        \n",
    "        return inputs, labels\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ab6b1ea-a5b6-489e-bcd4-da98d65b5b31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([785])\n",
      "torch.Size([785])\n"
     ]
    }
   ],
   "source": [
    "# taking the dataset for a spin\n",
    "sample_dataset = MNISTDataset(\"train.csv\", )\n",
    "x,y = next(iter(sample_dataset))\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93a613c4-55f4-4a9a-b526-7d5f0e8c7b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split dataset into train and validation\n",
    "validation_fraction = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "whole_dataset = MNISTDataset(\"train.csv\")\n",
    "split_idx = int(len(whole_dataset)*validation_fraction)\n",
    "\n",
    "val_indices = [i for i in range(0,split_idx)]\n",
    "train_indices = [i for i in range(split_idx, len(whole_dataset))]\n",
    "\n",
    "val_set = Subset(whole_dataset, val_indices)\n",
    "train_set = Subset(whole_dataset, train_indices)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69f77af0-1ab9-410e-9086-f63e83eba8b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f639095e-0902-4785-9fc2-27356fb167df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 785]), torch.Size([64, 785]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a0cb32-2e80-4f2d-9336-47c7964aa26e",
   "metadata": {},
   "source": [
    "# GPT!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1da97900-0f55-4afa-abf7-70ebed313f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class NewGELU(nn.Module):\n",
    "#     def forward(self,x):\n",
    "#         return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e1b5e1b-7f2d-4e2a-95d0-32f83383eb43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GPTConfig:\n",
    "    block_size: int = 786\n",
    "    vocab_size: int = 320\n",
    "    n_layer: int = 4   # Reduced number of layers\n",
    "    n_head: int = 4    # Reduced number of heads\n",
    "    n_embd: int = 256  # Reduced embedding size\n",
    "    dropout: float = 0.1\n",
    "    bias: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa5f7d84-4095-42a2-bd34-df4adfa652ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6897cfc1-1291-4bd4-a11e-71f7923aafb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # key, query, value projection\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        \n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        \n",
    "        # self.dropout = nn.Dropout(config.dropout)\n",
    "        \n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                             .view(1,1,config.block_size, config.block_size))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # (B, T, C)\n",
    "        \n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)  # (B, T, 3C) --> (B, T, C) (x 3)\n",
    "        \n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, n_h, T, h_dim)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1,2) # (B, n_h, T, h_dim)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1,2) # (B, n_h, T, h_dim)\n",
    "        \n",
    "        att_scores = (q @ k.transpose(-1, -2)) * (1.0 / math.sqrt(k.size(-1))) # (B, n_h, T, T)\n",
    "        att_scores = att_scores.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf')) \n",
    "        \n",
    "        # print(att_scores.shape)\n",
    "        att_scores = F.softmax(att_scores, dim=-1) # (B, n_h, T, T)\n",
    "        # print(att_scores)\n",
    "        \n",
    "        \n",
    "        att_scores = self.attn_dropout(att_scores)\n",
    "        \n",
    "        out = att_scores @ v # (B, n_h, T, h_dim)\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        \n",
    "        out = self.resid_dropout(self.c_proj(out))\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c6c0ab17-44f1-47fc-9b46-c84590e1a1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4*config.n_embd, bias=config.bias)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.c_proj = nn.Linear(4*config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6db87a0f-3603-487e-8321-235c58322cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d41e749e-0410-4e59-9897-8635787e928d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, config.bias)  \n",
    "        ))\n",
    "        \n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.lm_head.weight = self.transformer.wte.weight\n",
    "        \n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "        \n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2* config.n_layer))\n",
    "        print(f\"number of parameters: {self.get_num_params()/1e6:.4f}\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "                \n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        if non_embedding:\n",
    "            n_params = total_params - self.transformer.wpe.weight.numel()\n",
    "        return n_params\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        # targets: (B, T)\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        pos = torch.arange(0, t, device=device, dtype=torch.long)\n",
    "        \n",
    "        # forward the GPT model\n",
    "        tok_emb = self.transformer.wte(idx) # (B,T) --> (B, T, C)\n",
    "        pos_emb = self.transformer.wpe(pos) # (T) --> (1, T, C)\n",
    "        \n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        \n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.transformer.ln_f(x)\n",
    "        \n",
    "        \n",
    "        if targets is not None:\n",
    "            logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "            return logits, loss\n",
    "            \n",
    "        else:\n",
    "            logits = self.lm_head(x[:, [-1], :])\n",
    "            return logits, None\n",
    "    \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, temperature=1.0, do_sample=False, top_k=None):\n",
    "        \n",
    "        while idx.size(1) < self.config.block_size:\n",
    "            \n",
    "            print(idx.size(1))\n",
    "            # print(idx.shape)\n",
    "            logits, _ = self(idx)\n",
    "            # print(logits.shape)\n",
    "            \n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            \n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "                \n",
    "            # print(logits.shape)\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # print(probs.shape)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "            \n",
    "        \n",
    "        return idx           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0db349-1fa5-42da-84f1-26a63ae0100f",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2be71207-1923-4e41-9a6e-b764d38b0009",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 3.2415\n"
     ]
    }
   ],
   "source": [
    "model = GPT(GPTConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cedeb450-294c-4899-8897-97bc9eacb8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "num_epochs = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print_every = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db6822a5-5878-4853-8dcc-e862ea69a380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0, Loss: 0.6830\n",
      "Epoch: 0, Iteration: 50, Loss: 0.6643\n",
      "Epoch: 0, Iteration: 100, Loss: 0.6898\n",
      "Epoch: 0, Iteration: 150, Loss: 0.6610\n",
      "Epoch: 0, Iteration: 200, Loss: 0.6815\n",
      "Epoch: 0, Iteration: 250, Loss: 0.6797\n",
      "Epoch: 0, Iteration: 300, Loss: 0.6402\n",
      "Epoch: 0, Iteration: 350, Loss: 0.7134\n",
      "Epoch: 0, Iteration: 400, Loss: 0.6637\n",
      "Epoch: 0, Iteration: 450, Loss: 0.6485\n",
      "Epoch: 0, Iteration: 500, Loss: 0.6594\n",
      "Epoch: 0, Iteration: 550, Loss: 0.6630\n",
      "Epoch 0, Validation Loss: 0.6461\n",
      "Epoch 0 Summary: Train Loss: 0.6675, Validation Loss: 0.6461\n",
      "Epoch: 1, Iteration: 0, Loss: 0.6740\n",
      "Epoch: 1, Iteration: 50, Loss: 0.6492\n",
      "Epoch: 1, Iteration: 100, Loss: 0.6449\n",
      "Epoch: 1, Iteration: 150, Loss: 0.6486\n",
      "Epoch: 1, Iteration: 200, Loss: 0.6446\n",
      "Epoch: 1, Iteration: 250, Loss: 0.6982\n",
      "Epoch: 1, Iteration: 300, Loss: 0.6443\n",
      "Epoch: 1, Iteration: 350, Loss: 0.6389\n",
      "Epoch: 1, Iteration: 400, Loss: 0.6778\n",
      "Epoch: 1, Iteration: 450, Loss: 0.6205\n",
      "Epoch: 1, Iteration: 500, Loss: 0.6115\n",
      "Epoch: 1, Iteration: 550, Loss: 0.6360\n",
      "Epoch 1, Validation Loss: 0.6353\n",
      "Epoch 1 Summary: Train Loss: 0.6546, Validation Loss: 0.6353\n",
      "Epoch: 2, Iteration: 0, Loss: 0.6936\n",
      "Epoch: 2, Iteration: 50, Loss: 0.6685\n",
      "Epoch: 2, Iteration: 100, Loss: 0.6672\n",
      "Epoch: 2, Iteration: 150, Loss: 0.6179\n",
      "Epoch: 2, Iteration: 200, Loss: 0.6282\n",
      "Epoch: 2, Iteration: 250, Loss: 0.6281\n",
      "Epoch: 2, Iteration: 300, Loss: 0.6416\n",
      "Epoch: 2, Iteration: 350, Loss: 0.6222\n",
      "Epoch: 2, Iteration: 400, Loss: 0.6271\n",
      "Epoch: 2, Iteration: 450, Loss: 0.6719\n",
      "Epoch: 2, Iteration: 500, Loss: 0.6398\n",
      "Epoch: 2, Iteration: 550, Loss: 0.6611\n",
      "Epoch 2, Validation Loss: 0.6234\n",
      "Epoch 2 Summary: Train Loss: 0.6435, Validation Loss: 0.6234\n",
      "Epoch: 3, Iteration: 0, Loss: 0.6310\n",
      "Epoch: 3, Iteration: 50, Loss: 0.6537\n",
      "Epoch: 3, Iteration: 100, Loss: 0.6238\n",
      "Epoch: 3, Iteration: 150, Loss: 0.6376\n",
      "Epoch: 3, Iteration: 200, Loss: 0.6290\n",
      "Epoch: 3, Iteration: 250, Loss: 0.6177\n",
      "Epoch: 3, Iteration: 300, Loss: 0.6023\n",
      "Epoch: 3, Iteration: 350, Loss: 0.5986\n",
      "Epoch: 3, Iteration: 400, Loss: 0.6428\n",
      "Epoch: 3, Iteration: 450, Loss: 0.6616\n",
      "Epoch: 3, Iteration: 500, Loss: 0.6523\n",
      "Epoch: 3, Iteration: 550, Loss: 0.5962\n",
      "Epoch 3, Validation Loss: 0.6160\n",
      "Epoch 3 Summary: Train Loss: 0.6337, Validation Loss: 0.6160\n",
      "Epoch: 4, Iteration: 0, Loss: 0.6053\n",
      "Epoch: 4, Iteration: 50, Loss: 0.6302\n",
      "Epoch: 4, Iteration: 100, Loss: 0.6012\n",
      "Epoch: 4, Iteration: 150, Loss: 0.6206\n",
      "Epoch: 4, Iteration: 200, Loss: 0.5999\n",
      "Epoch: 4, Iteration: 250, Loss: 0.6268\n",
      "Epoch: 4, Iteration: 300, Loss: 0.6113\n",
      "Epoch: 4, Iteration: 350, Loss: 0.6582\n",
      "Epoch: 4, Iteration: 400, Loss: 0.6295\n",
      "Epoch: 4, Iteration: 450, Loss: 0.5896\n",
      "Epoch: 4, Iteration: 500, Loss: 0.6649\n",
      "Epoch: 4, Iteration: 550, Loss: 0.6349\n",
      "Epoch 4, Validation Loss: 0.6072\n",
      "Epoch 4 Summary: Train Loss: 0.6250, Validation Loss: 0.6072\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, loader, optimizer, epoch_num, device, log_every=50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % log_every == 0:\n",
    "            print(f\"Epoch: {epoch_num}, Iteration: {i}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def validation_epoch(model, loader, epoch_idx, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits, loss = model(x, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    val_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch_idx}, Validation Loss: {val_loss:.4f}\")\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, i, device)\n",
    "    val_loss = validation_epoch(model, val_loader, i, device)\n",
    "    print(f\"Epoch {i} Summary: Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8c061f70-c324-4264-8ba7-c4302047480c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6cdb590d10>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "desired_number = 2\n",
    "idx = torch.tensor([256+desired_number])[None, :].to(device)\n",
    "output = model.generate(idx)\n",
    "plt.imshow(output.cpu()[0, 1:-1].contiguous().view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600a0c7-fc24-4c86-85a6-7d5f0fa3bb48",
   "metadata": {
    "tags": []
   },
   "source": [
    "# evaluation / super cool gif generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16dd9c93-cdc5-439a-b8d3-e994dcc44694",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7773e6-7155-433a-9a03-1b374c751613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
